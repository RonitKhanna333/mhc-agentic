# Choose provider: 'groq' or 'gemini'
LLM_PROVIDER=groq

# Debug mode - show all internal processing (true/false)
DEBUG_MODE=false

# Groq API (OpenAI-compatible)
GROQ_API_KEY=your_groq_api_key_here

# Expert agents use smaller, faster model with RAG
GROQ_MODEL=llama-3.1-8b-instant

# Master agent uses larger model for better synthesis
GROQ_MASTER_MODEL=llama-3.3-70b-versatile

# Available Groq models:
# - llama-3.1-8b-instant (fast, smaller, good with RAG)
# - llama-3.3-70b-versatile (larger, better reasoning)
# - mixtral-8x7b-32768 (alternative)

# Gemini API
GEMINI_API_KEY=your_gemini_api_key_here

# Expert agents model
GEMINI_MODEL=gemini-1.5-flash

# Master agent model
GEMINI_MASTER_MODEL=gemini-1.5-pro

# Available Gemini models:
# - gemini-1.5-flash (fast, smaller)
# - gemini-1.5-pro (larger, better quality)
# - gemini-1.0-pro (older)
